TODO:

check rocksdb + wiredtiger + cockroachdb

Use __thread instead of thread_local
classes outside defn

===========
"core/app-template.hh"

main() {
	app_template app;

	app.add_options() // uses boost program_options

	app.run(argc, argv, func);
}

"core/distributed.hh"

distributed<TypeName>

reactor::engine

smp_message_queue
syscall_work_queue

from pipe.hh
/// Repeat a blocking task indefinitely            | \ref keep_doing()
/// Repeat a blocking task, then exit              | \ref repeat(), \ref do_until()
/// Provide mutual exclusion between two tasks     | \ref semaphore, \ref shared_mutex
/// Pass a stream of data between two fibers       | \ref seastar::pipe
/// Safely shut down a resource                    | \ref seastar::gate, \ref seastar::with_gate()
/// Hold on to an object while a fiber is running  | \ref do_with()

========

API 

CORE

futurize ?
do_with

make_lw_shared

engine().open_directory()
engine().net().connect()
engine().listen()

engine().at_exit()
engine().exit()

engine().cpu_id()
smp::submit_to()
smp::count

rwlock are per CPU

derive from async_sharded_service
declare distributed<T> v, then use 
v.local() 
v.invoke_on_all()
v.map_reduce()
parallel_for_each
keep_doing

========

std::future is not thread-safe
std::future::wait() implemented using condition variable
https://gcc.gnu.org/onlinedocs/gcc-4.6.2/libstdc++/api/a00888_source.html

seastar::future::wait() - calls switch_out()

thread
thread_context - setjmp, longjmp used for co-operative multitasking
yield
should_yield
=======

NET directory
=======

std::async replaced by seastar::async

is_future<ret_type>::value
std::is_lvalue_reference<Func>::value

=======


Reactor pattern
How to start process ? 

	app_template.run
	  reactor.run 
		reactor.run_tasks
		poll_queues
		  process_incoming
		  process_completions

reactor is per-core
reactor has
{
_thread_pool -> has syscall_work_queue(inter_thread_wq)
_signals
_pending_tasks
_network_task
}

All these pollers are added as tasks (engine().add_task())
smp_poller
io_poller
sig_poller
aio_poller - _pending_aio
batch_flush_poller
drain_cross_cpu_freelist
expire_lowres_timers

How to yield CPU
How to find load on a core : _loads
How to handle blocking IO 
Signal handling
Network calls

NUMA-aware Memory allocation
	declare per-thread memory allocator? - not really per-CPU
	embed cpu_id in memory allocatd (object_cpu_id)
	mmap allocator
 -> cpu_pages::cpu_mem is thread_local
    cpu_pages::all_cpus 

All file IO is done via thread_pool->inter_thread_wq
It starts a _worker_thread which calls thread_pool::work()

===

foreign_ptr <=> make_foreign

lw_shared_ptr <=> make_lw_shared

net::get_local_

future <=> make_ready_future, make_empty


========

memory::stats().total_memory()

===========

OLD


Seastar

Uses setjmp, longjmp for cooperative multitasking (thread_context)
seastar::future::wait() calls switch_out

Reactor pattern used
Per-core Reactor is defined and accessed via "engine()".

Code flow is as follows

app_template.run()
->reactor.run()
  ->reactor.run_tasks()
    ->poll_queues()

To define a per-CPU object,
define "distributed<class> obj"
and access as "obj.local()" or "obj.invoke_all()"

Alternately, derive from async_sharded_service

Submit task to another CPU
smp::submit_to()

To find load on core, use engine()._loads

Disk IO
is non-blocking
When you call (e.g) engine().open_directory()
This submits IO to thread_pool->inter_thread_wq
thread_pool has a dedicated "_worker_thread" which is looping in thread_pool::work()

Memory allocation:
use thread_local to define per-thread memory allocators
memory for different cpus map at different location in proc add space
	auto base = mem_base() + (size_t(cpu_id) << cpu_id_shift);
can infer cpu_id from ptr 
cpu_pages::cpu_mem is thread_local
cpu_pages::all_cpus

it links with -lhwloc -lnuma -lpciaccess 

Network stack:
engine().listen()

Supports Lightweight objects
rwlock 
lw_shared_ptr
future

Other goodies
parallel_for_each
keep_doing
Keep objects alive using "do_with"
seastar::gate
seastar::pipe

"core/app-template.hh"

main() {
    app_template app;

    app.add_options() // uses boost program_options

    app.run(argc, argv, func);
}
