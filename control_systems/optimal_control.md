
Given a dynamical system, the control aim is to maximize objective function

* Dynamic programming
* Pontryagin maximum principle
* Numerical techniques for trajectory optimization

Pontryagin's minimum principle is a necessary condition for an optimum. The Hamilton-Jacobi-Bellman equation provides sufficient conditions for an optimum.

http://en.wikipedia.org/wiki/Optimal_control

http://en.wikipedia.org/wiki/Pontryagin%27s_maximum_principle

http://www.scholarpedia.org/article/Optimal_control


* Lewis Optimal Control
* Stengel Optimal control and estimation
* Bryson Applied Optimal Control
* Hull Optimal control theory for applications
* Serovaiskii Counterexamples in optimal control theory
* Krotov Global methods in optimal control theory
* Seierstad Optimal control theory with economic applications
* Gamkrelidze Principles of optimal control theory
* Berkovitz Optimal control theory
* Kirk Optimal control theory; an introduction
* Strauss An introduction to optimal control theory.
* Young Lectures on the calculus of variations and optimal control theory
* Lee, markus Foundations of optimal control theory
* Hestenes Calculus of variations and optimal control theory

