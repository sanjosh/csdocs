
https://github.com/valeman/awesome-conformal-prediction

https://arxiv.org/abs/2206.04301 (how transformer learn; Unveiling Transformers with LEGO: a synthetic reasoning task
)

step-by-step guide on coding BERT, GPT, BART from the ground up
https://github.com/dpressel/mint

colm maccarthaigh rules for credentials:
need revocation, not rotation
have closed loops : when you remove credential, see it gone before deactivating
need to see where and when credential is used
beware of time-based expiry
store credentials only where they are needed
replacing credentials usually exposes them to more systems
do asymmetric where you can, if not, use compute-intensive hashing or derived key symmetric.
keep credentials inside one-way enclaves like TPM, TEE, HSM
check for all-zeroes creds and repeated values

https://mlengineer.io/
https://github.com/khangich/machine-learning-interview

https://thesequence.substack.com/p/-edge124-transformer-architectures
5 famous transformer architectures:
1. @GoogleAI Switch Transformer
2. @GoogleAI BERT
3. @OpenAI GPT-3
4. @OpenAI ImageGPT
5. @DeepMind compressive transformer

90 python projects https://medium.com/coders-camp/96-python-projects-with-source-code-4069eb58beef

how git works https://towardsdatascience.com/how-git-truly-works-cd9c375966f6

transformer applications https://github.com/NielsRogge/Transformers-Tutorials

zero and few-shot learning NLP https://github.com/allenai/acl2022-zerofewshot-tutorial

automated crossword puzzle solving  https://arxiv.org/abs/2205.09665

https://towardsdatascience.com/the-similarity-between-t-sne-umap-pca-and-other-mappings-c6453b80f303

redshift https://www.amazon.science/latest-news/amazon-redshift-ten-years-of-continuous-reinvention

Gato Agent 
https://storage.googleapis.com/deepmind-media/A%20Generalist%20Agent/Generalist%20Agent.pdf

Simple Tricks Improve Systematic Generalization of Transformers`
https://paperswithcode.com/paper/the-devil-is-in-the-detail-simple-tricks

ML python libraries https://github.com/ml-tooling/best-of-ml-python

Tortoise zero shot multivoice TTS https://github.com/neonbjb/tortoise-tts

recommender systems nvidia https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e

Berkeley EECS 208 "Computational Principles for High-dimensional Data Analysis https://book-wright-ma.github.io/Lecture-Slides/

Graph Neural Networks (GNNs) with Learnable Structural and Positional Representations

https://wandb.ai/sauravmaheshkar/gnn-lspe/reports/Graph-Neural-Networks-GNNs-with-Learnable-Structural-and-Positional-Representations--VmlldzoxNDY5MDc5?galleryTag=posts


https://github.com/ytdl-org/youtube-dl/
how to execute zip file in python
```
echo '#!/usr/bin/python' > file
echo zip >> file
```

machine learning system design
https://stanford-cs329s.github.io/syllabus.html

Probability Distribution in Monopoly Using Markov Chains
https://abakcus.com/directory/probability-distribution-in-monopoly-using-markov-chains/

Yann LeCun "A path towards Autonomous AI"
https://www.youtube.com/watch?v=DokLw1tILlw&feature=youtu.be

Recommender system Even Oldridge
NCF, DeepFM, Wide and Deep, DLRM, DCN, BST
https://twitter.com/radekosmulski/status/1496862506324672515

Deepmind Oxford lectures NLP https://github.com/oxford-cs-deepnlp-2017

Harvard CS 224: Advanced Algorithms course
http://people.seas.harvard.edu/~minilek/cs224/fall14/index.html

"An Introduction to Neural Data Compression, how generative models such as GANs, VAEs, and flows can revolutionize codec design 
https://arxiv.org/pdf/2202.06533.pdf

Anomaly detection https://arxiv.org/abs/2009.11732

React patterns book Osmani https://www.patterns.dev/

Dittrich The Case for Automatically Generated Index Structures https://www.vldb.org/pvldb/vol15/p527-dittrich.pdf

Netflix recommender systems https://ojs.aaai.org/index.php/aimagazine/article/view/18140

"Introduction to Uncertainty in Deep Learning" http://www.gatsby.ucl.ac.uk/~balaji/balaji-uncertainty-talk-cifar-dlrl.pdf

Color scale for data https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/

COIN : a new approach for image compression: instead of storing the pixels in an image, we store the weights of an MLP overfitted to the image üåü At low bit-rates this can do better than JPEG!
https://arxiv.org/abs/2103.03123

translate image to maps using transformers 
problem of constructing a top-down ‚Äúbird‚Äôs-eye‚Äù view of a scene on the basis of standard sideways-on photographs.
https://www.amazon.science/blog/translating-images-into-birds-eye-view-maps

polyfuzz
https://github.com/MaartenGr/PolyFuzz

Autoregressive Search Engines: Generating Substrings as Document Identifiers
guided LM decoding to search for occurrences of ngrams of any size in an arbitrary large collection of documents.
https://github.com/facebookresearch/SEAL
https://arxiv.org/abs/2204.10628

S4
The Structured State Space for Sequence Modeling (S4) architecture is a new approach to very long-range sequence modeling tasks for vision, language, and audio, showing a capacity to capture dependencies over tens of thousands of steps.
https://srush.github.io/annotated-s4/



Pix2Seq 
http://arxiv.org/abs/2109.10852
cast object detection as a language modeling task conditioned on pixels!

relational ML
https://towardsdatascience.com/what-is-relational-machine-learning-afbe4a9c4231

how do transformer LMs construct predictions? 
We tackle this question by reverse-engineering the FFN layers in LMs and the mechanism in which they update the prediction across layer
https://github.com/aviclu/ffn-values


Sampling design and analysis
https://statmodeling.stat.columbia.edu/2022/03/09/sampling-design-and-analysis-third-edition-by-sharon-lohr/

Concrete introduction to Probability Norvig
https://github.com/norvig/pytudes/blob/main/ipynb/Probability.ipynb

Peter Burka on Crossing the Gap from Imperative to Functional Programming through Refactoring - originally posted on Nov 3, 2014
https://www.youtube.com/watch?v=nEwQJDv7QdI

Transformer memory as differentiable search index
https://arxiv.org/abs/2202.06991

Transformer recipe https://github.com/dair-ai/Transformers-Recipe/blob/main/README.md

DeepETA https://eng.uber.com/deepeta-how-uber-predicts-arrival-times/

Tabular data
1. LightGBM/XGBoost/Catboost
2. MLP
3. 1D-CNN
4. TabNet
5. nvidia cuML SVM

DeepMind alphacode 
https://www.youtube.com/watch?v=YjsoN5aJChA
https://www.deepmind.com/blog/article/Competitive-programming-with-AlphaCode
https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf

GNN
https://twitter.com/omarsar0/status/1490276912601653248

- Graph Neural Networks: Methods, Applications, and Opportunities: https://arxiv.org/abs/2108.10733
- A Comprehensive Survey on Graph Neural Networks: https://arxiv.org/abs/1901.00596

Gentle intro to GNNs (by @distillpub): https://distill.pub/2021/gnn-intro/
- Foundations of GNNs (by @PetarV_93): https://youtube.com/watch?v=uF53xsT7mjc&ab_channel=PetarVeli%C4%8Dkovi%C4%87
- Graph Convolutional Networks (by @thomaskipf): http://tkipf.github.io/graph-convolutional-networks/

- Geometric Deep Learning (by @mmbronstein et al): https://geometricdeeplearning.com - Graph Representation Learning Book (by William Hamilton): https://cs.mcgill.ca/~wlh/grl_book/
- CS224W: ML with Graphs (by @jure): https://youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn

Fastai: A Layered API for Deep Learning
https://www.mdpi.com/2078-2489/11/2/108

ctypes
https://leimao.github.io/blog/Python-C-Library-Function-Binding-Using-ctypes/

"Information theory, inference and learning algorithms" by Sir MacKay
https://www.inference.org.uk/itila/book.html

Search - Query Matching via Lexical, Graph, and Embedding Methods
https://eugeneyan.com/writing/search-query-matching/

CIDR 2021 databases https://www.cidrdb.org/cidr2021/program.html

microbenchmarks
https://www.youtube.com/watch?v=0jI-AlWEwYI&list=WL&index=6

cameras and lenses
https://ciechanow.ski/cameras-and-lenses/

transformers trends
https://syncedreview.com/2020/12/15/neurips-2020-teaching-transformers-new-tricks/
http://gsarti.com/post/iclr2020-transformers/

JIT compiler in PHP
https://www.slideshare.net/nikita_ppv/justintime-compiler-in-php-8

DeepRL https://spinningup.openai.com/en/latest/

RL vision https://distill.pub/2020/understanding-rl-vision/
, we apply interpretability techniques to a reinforcement learning (RL) model trained to play the video game CoinRun
[1]
. Using attribution
[2, 3, 4, 5, 6, 7, 8, 9]
 combined with dimensionality reduction as in
[10]
, we build an interface for exploring the objects detected by the model, and how they influence its value function and policy. We leverage this interface in several way

python3.9 library index
https://gist.github.com/jph00/d5981f649a83a754946964cf22322cb2

transformer encoder visualize https://github.com/mertensu/transformer-tutorial

array programming with numpy https://www.nature.com/articles/s41586-020-2649-2

matplotlib - picture in picture https://matplotlib.org/3.1.1/gallery/subplots_axes_and_figures/zoom_inset_axes.html

ML courses https://github.com/luspr/awesome-ml-courses/

Executable semantic parsing https://cs.stanford.edu/~pliang/papers/executable-cacm2016.pdf

mFST, a Python library for working with Finite-State Machines with Custom Semirings
https://github.com/matthewfl/openfst-wrapper/


Deep reinforcement learning book
https://github.com/kengz/SLM-Lab
https://www.amazon.com/dp/0135172381/

GAN CS294-158 Berkeley
https://www.youtube.com/watch?v=1CT-kxjYbFU&feature=youtu.be
https://github.com/rll/deepul/blob/master/demos/lecture5_gan_models_demos.ipynb
https://drive.google.com/file/d/1qCVpu2zFz1uEe3QcNHGlaT1Rs2u8HrCc/view


alec radford language models
https://www.youtube.com/watch?v=BnpB3GrpsfM

self supervised learning
https://www.youtube.com/watch?v=dMUes74-nYY

submarine torpedo tubes
https://www.thedrive.com/the-war-zone/35794/this-explainer-on-how-wonderfully-complex-submarine-torpedo-tubes-are-is-a-must-watch

SwAV self-supervised learning
https://arxiv.org/abs/2006.09882
https://www.youtube.com/watch?v=7QmsTleiRLs&t=3s

google authenticator
https://twitter.com/alexxubyte/status/1549781763999744000
https://threadreaderapp.com/thread/1549781763999744000.html

DynamoDB usenix 2022
https://www.usenix.org/system/files/atc22-elhemali.pdf
https://brooker.co.za/blog/2022/07/12/dynamodb.html

Firebase cloud messaging
https://twitter.com/alexxubyte/status/1545074972858535936
https://threadreaderapp.com/thread/1545074972858535936.html

python decorators
https://muellerzr.github.io/fastblog/python/2022/07/06/Decorators.html

contrastive  data and learning
https://contrastive-nlp-tutorial.github.io/

pandas data structures
https://twitter.com/thedataprof/status/1543420744725475330
https://towardsdatascience.com/how-to-master-pandas-for-data-science-b8ab0a9b1042

effective pandas book
https://github.com/mattharrison/effective_pandas_book

pen and paper exercises in ML Michael Guttmann
This is a collection of (mostly) pen-and-paper exercises in machine learning. The exercises are on the following topics: linear algebra, optimisation, directed graphical models, undirected graphical models, expressive power of graphical models, factor graphs and message passing, inference for hidden Markov models, model-based learning (including ICA and unnormalised models), sampling and Monte-Carlo integration, and variational inference.
https://arxiv.org/abs/2206.13446

Dirtycat data cleaning
https://dirty-cat.github.io/stable/

filters in databases
ribbon http://rocksdb.org/blog/2021/12/29/ribbon-filter.html
proteus https://dl.acm.org/doi/10.1145/3514221.3526167
workload adaptive filtering https://dl.acm.org/doi/abs/10.1145/3514221.3520256

sklearn with transformers
https://www.kaggle.com/code/unofficialmerve/scikit-learn-with-transformers

exploring economics
https://www.exploring-economics.org/en/

foundation models
https://arxiv.org/pdf/2205.09911.pdf
https://github.com/HazyResearch/fm_data_tasks

alphacode explained https://www.reddit.com/r/MachineLearning/comments/slwh69/p_alphacode_explained/

testing distributed systems
https://asatarin.github.io/testing-distributed-systems/

latent variables techniques in UX
factor analysis
latent class analysis
structural equation modeling
rasch analysis
https://measuringu.com/latent-variables/

SVD 
1. how to impute missing values, 
2. matrix compression
3. check multi-collinearity
https://www.govindgnair.com/post/svd-is-almost-all-you-need/

time series trends
https://towardsdatascience.com/breakthroughs-in-time-series-forecasting-at-neurips-2020-1dc1b9b6d99d

coordinate system for chemical elements - variational autoencoders
https://deepai.org/publication/ai-discovering-a-coordinate-system-of-chemical-elements-dual-representation-by-variational-autoencoders

calibrating classifiers
CalibratedClassiferCV sklearn
https://towardsdatascience.com/calibrating-classifiers-559abc30711a

A Survey of Neural Networks and Formal Languages
https://arxiv.org/abs/2006.01338

physics based learning
https://deepai.org/publication/how-to-do-physics-based-learning

so many different ways to inject noise in training for regularization:
- Gradient noise
- layer noise
- structure noise (dropout/dropconnect)
- input noise
- quantization noise 
https://arxiv.org/abs/2004.07320

relationship between the mean, median, and standard deviation. If the distribution has finite variance, then the distance between the median and the mean is bounded by one standard deviation.
https://twitter.com/docmilanfar/status/1244063988914110464

simple problems that ML cannot solve
https://www.reddit.com/r/MachineLearning/comments/ijtolv/d_what_are_some_relatively_simple_problems_that/

how mandelbrot sets emerge
https://www.youtube.com/watch?v=FFftmWSzgmk

compress the maps
learn to compress the map representation such that it is optimal for the localization task
https://deepai.org/publication/learning-to-localize-through-compressed-binary-maps


neural scaling laws , bahri, dyer, kaplan, lee, sharma
https://syncedreview.com/2021/02/18/google-jhu-paper-explores-and-categorizes-neural-scaling-laws/
https://arxiv.org/pdf/2102.06701.pdf

pca implemented from scratch
https://twitter.com/python_engineer/status/1456573392769986562

pca https://twitter.com/karlrohe/status/1472886848582299650

emergent abilities in large LM
https://arxiv.org/abs/2206.07682

Metarank
open-source real-time personalization engine.
It can rerank products, posts, or ads to improve conversion and engagement.
https://github.com/metarank/metarank

snapshots of modern math
https://www.mfo.de/outreach-media/snapshots

tools for exploring data
autoplotter
bamboolib
bitrook
dabl
dataprep
D-tale
explainerdashboard
klib
mita
pandas_UI
pandas-gui
pandas profiing
sweetviz


deep generative modeling
https://jmtomczak.github.io/blog.html


scutoid, a geometrical shape new to math, but not to nature ‚Äî is the form that a group of cells in the body takes in order to pack tightly and efficiently into the tricky curves of organs
https://www.livescience.com/63207-scutoid-new-shape-nature.html


Approximating How Single Head Attention Learns
Why does model often attend to salient words even though it's not required by the training loss? To understand this inductive bias we need to analyze the optimization trajectory
https://arxiv.org/pdf/2103.07601.pdf

representation learning in limited data
Gael varoquaux

physics of resonance
https://www.quantamagazine.org/how-the-physics-of-resonance-shapes-reality-20220126/
https://www.slideshare.net/GaelVaroquaux/representation-learning-in-limiteddata-settings-250095542
