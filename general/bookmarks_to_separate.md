
https://github.com/valeman/awesome-conformal-prediction

https://arxiv.org/abs/2206.04301 (how transformer learn; Unveiling Transformers with LEGO: a synthetic reasoning task
)

step-by-step guide on coding BERT, GPT, BART from the ground up
https://github.com/dpressel/mint

colm maccarthaigh rules for credentials:
need revocation, not rotation
have closed loops : when you remove credential, see it gone before deactivating
need to see where and when credential is used
beware of time-based expiry
store credentials only where they are needed
replacing credentials usually exposes them to more systems
do asymmetric where you can, if not, use compute-intensive hashing or derived key symmetric.
keep credentials inside one-way enclaves like TPM, TEE, HSM
check for all-zeroes creds and repeated values

https://mlengineer.io/
https://github.com/khangich/machine-learning-interview

https://thesequence.substack.com/p/-edge124-transformer-architectures
5 famous transformer architectures:
1. @GoogleAI Switch Transformer
2. @GoogleAI BERT
3. @OpenAI GPT-3
4. @OpenAI ImageGPT
5. @DeepMind compressive transformer

90 python projects https://medium.com/coders-camp/96-python-projects-with-source-code-4069eb58beef

how git works https://towardsdatascience.com/how-git-truly-works-cd9c375966f6

transformer applications https://github.com/NielsRogge/Transformers-Tutorials

zero and few-shot learning NLP https://github.com/allenai/acl2022-zerofewshot-tutorial

automated crossword puzzle solving  https://arxiv.org/abs/2205.09665

https://towardsdatascience.com/the-similarity-between-t-sne-umap-pca-and-other-mappings-c6453b80f303

redshift https://www.amazon.science/latest-news/amazon-redshift-ten-years-of-continuous-reinvention

Gato Agent 
https://storage.googleapis.com/deepmind-media/A%20Generalist%20Agent/Generalist%20Agent.pdf

Simple Tricks Improve Systematic Generalization of Transformers`
https://paperswithcode.com/paper/the-devil-is-in-the-detail-simple-tricks

ML python libraries https://github.com/ml-tooling/best-of-ml-python

Tortoise zero shot multivoice TTS https://github.com/neonbjb/tortoise-tts

recommender systems nvidia https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e

Berkeley EECS 208 "Computational Principles for High-dimensional Data Analysis https://book-wright-ma.github.io/Lecture-Slides/

Graph Neural Networks (GNNs) with Learnable Structural and Positional Representations

https://wandb.ai/sauravmaheshkar/gnn-lspe/reports/Graph-Neural-Networks-GNNs-with-Learnable-Structural-and-Positional-Representations--VmlldzoxNDY5MDc5?galleryTag=posts


https://github.com/ytdl-org/youtube-dl/
how to execute zip file in python
```
echo '#!/usr/bin/python' > file
echo zip >> file
```

machine learning system design
https://stanford-cs329s.github.io/syllabus.html

Probability Distribution in Monopoly Using Markov Chains
https://abakcus.com/directory/probability-distribution-in-monopoly-using-markov-chains/

Yann LeCun "A path towards Autonomous AI"
https://www.youtube.com/watch?v=DokLw1tILlw&feature=youtu.be

Recommender system Even Oldridge
NCF, DeepFM, Wide and Deep, DLRM, DCN, BST
https://twitter.com/radekosmulski/status/1496862506324672515

Deepmind Oxford lectures NLP https://github.com/oxford-cs-deepnlp-2017

Harvard CS 224: Advanced Algorithms course
http://people.seas.harvard.edu/~minilek/cs224/fall14/index.html

"An Introduction to Neural Data Compression, how generative models such as GANs, VAEs, and flows can revolutionize codec design 
https://arxiv.org/pdf/2202.06533.pdf

Anomaly detection https://arxiv.org/abs/2009.11732

React patterns book Osmani https://www.patterns.dev/

Dittrich The Case for Automatically Generated Index Structures https://www.vldb.org/pvldb/vol15/p527-dittrich.pdf

Netflix recommender systems https://ojs.aaai.org/index.php/aimagazine/article/view/18140

"Introduction to Uncertainty in Deep Learning" http://www.gatsby.ucl.ac.uk/~balaji/balaji-uncertainty-talk-cifar-dlrl.pdf

Color scale for data https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/

COIN : a new approach for image compression: instead of storing the pixels in an image, we store the weights of an MLP overfitted to the image ðŸŒŸ At low bit-rates this can do better than JPEG!
https://arxiv.org/abs/2103.03123
