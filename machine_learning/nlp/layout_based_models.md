
# Layout aware LAMBERT

https://arxiv.org/pdf/2002.08087.pdf

# LayoutLM

https://huggingface.co/microsoft/layoutlmv2-base-uncased

https://huggingface.co/transformers/model_doc/layoutlm.html

Inspired by the BERT model [4], where input textual information is mainly represented by text embeddings and position embeddings, LayoutLM further adds two types of input embeddings:

1. a 2-D position embedding that denotes the relative position of a token within a document;
2. an image embedding for scanned token images within a document.

We evaluate the LayoutLM model on three document image understanding tasks:

Form Understanding : This task requires extracting and structuring the textual content of forms. It aims to extract key-value pairs
from the scanned form images. I

Receipt Understanding : This task requires filling several predefined semantic slots according to the scanned receipt images

Document Image Classification : Given a visually rich document,
this task aims to predict the corresponding category for each document image

https://arxiv.org/pdf/1912.13318.pdf

# VIPS 

degree of coherence


