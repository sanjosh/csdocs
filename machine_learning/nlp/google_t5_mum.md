
# T5 - text to text tranfer

```
With T5, we propose reframing all NLP tasks into a unified text-to-text-format 
where the input and output are always text strings, in contrast to BERT-style 
models that can only output either a class label or a span of the input.

```

https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html

https://arxiv.org/abs/1910.10683

# MUM 

```
 MUM uses the T5 text-to-text framework and is 1,000 times more powerful than BERT. 
 MUM not only understands language, but also generates it. 
 Itâ€™s trained across 75 different languages and many different tasks at once, allowing it to develop 
 a more comprehensive understanding of information and world knowledge than previous models. 
 And MUM is multimodal, so it understands information across text and images and, 
 in the future, can expand to more modalities like video and audio.
```
https://blog.google/products/search/how-mum-improved-google-searches-vaccine-information/

```
 MultiModel is a first step towards the convergence of vision, audio and language understanding into a single network.

```

https://ai.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html

https://arxiv.org/abs/1706.05137
