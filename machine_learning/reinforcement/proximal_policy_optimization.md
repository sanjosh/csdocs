
# Proximal Policy Optimization.

1. builds on actor-critic
2. has sampling efficiency
3. minimal hyperparameter tuning

Upgrades

1. Generalized Advantage estimation  (GAE)
2. Surrogate policy loss function
3. Mini-batch updates


## GAE algorithm

new way to calculate returns which reduces variance

## surrogate policy loss

ratio of new probabilities/old probabilities

# References

https://www.youtube.com/watch?v=5P7I-xPq8u8

https://www.youtube.com/watch?v=WxQfQW48A4A&list=PLWzQK00nc192L7UMJyTmLXaHa3KcO0wBT&index=11

https://openai.com/blog/openai-baselines-ppo/
