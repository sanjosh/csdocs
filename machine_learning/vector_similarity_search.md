
Maximum inner product search

# learned quantization

Compress the vectors such that distance is approximated 

scheme where you minimize the average distance between each vector x and its quantized form 

# FAISS

## polysemous codes

offer both the distance estimation quality of product quantization and the efficient comparison of binary codes with Hamming distance.

https://arxiv.org/abs/1609.01882

## Billion-scale similarity search with GPUs

https://arxiv.org/abs/1702.08734

# SCANN

https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html

key idea : finding encodings with higher average distance may actually result in superior MIPS accuracy.

# list of inner product libraries

https://github.com/erikbern/ann-benchmarks#evaluated
