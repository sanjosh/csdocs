
Standard NN training via optimization is (from a probabilistic perspective) = MLE for the weights.

regularization = prior on weights; optimization is MAP estimator rather than MLE

BNN introduce posterior inference 

each weight of the network has its own mean and variance

https://www.kdnuggets.com/2017/12/what-bayesian-neural-network.html
