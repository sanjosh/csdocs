

in real neurons, there is no backprop.  synaptic symmetry required.  Weight transport problem

```
Training a neural network is a credit assignment problem: an update is derived for each parameter from its contribution to a cost function.
```

backprop requires transpose of weight matrix

DFA replaces it with a random projection of the topmost derivative of the loss, Î´a"


# references

Launay, Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architecture https://arxiv.org/pdf/2006.12878.pdf

Nokland, Direct feedback alignment provides learning

https://www.reddit.com/r/MachineLearning/comments/hgw9be/d_paper_explained_direct_feedback_alignment/
