
Rather than predicting classes, predict probabilities for those classes

# Platt scaling

# Isotonic regression

# Reliability diagram

A classification model is calibrated if its predicted probabilities of outcomes reflect their accuracy. 

https://en.wikipedia.org/wiki/Platt_scaling

experiments have shown that maximum margin methods such as SVM, boosted trees etc push the real posterior probability away from 0 and 1 while methods such as Naive Bayes tend to push the probabilities towards 0 and 1

https://www.analyticsvidhya.com/blog/2016/07/platt-scaling-isotonic-regression-minimize-logloss-error/

https://stats.stackexchange.com/questions/5196/why-use-platts-scaling

https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/

( Guo, On calibration of modern neural networks) http://proceedings.mlr.press/v70/guo17a/guo17a.pdf
