
# Bottleneck layer in CNN

https://stats.stackexchange.com/questions/262044/what-does-a-bottleneck-layer-mean-in-neural-networks

## Lim, CNN-based bottleneck feature


Bottleneck features generated from a multi-layer perceptron(MLP) is typically used for dimensionality reduction [14],[15]. Furthermore, several studies [16], [17] have been usedbottleneck features to improve performance in bad environ-mental conditions and have shown remarkable performanceimprovements.

[14] F. Grezl, M. Karafiat, S. Kontar, and J. Cernocky, “Probabilistic and bottleneck features for lvcsr of meetings,” inProceedings of theInternational Conference on Acoustics, Speech and Signal Processing(ICASSP), 2007, pp. 757–760.
[15] D. Yu and M. L. Seltzer, “Improved bottleneck features using pretrained deep neural networks,” inProceedings of INTERSPEECH, 2011, p. 240.
[16] H. Zhang, I. McLoughlin, and Y. Song, “Robust sound event recog-nition using convolutional neural networks,” inProceedings of theInternational Conference on Acoustics, Speech and Signal Processing(ICASSP), 2015, pp. 559–563.[17] T. Yamada, L. Wang, and A. Kai, “Improvement of distant-talking speaker identification using bottleneck features of dnn,” in Proceedingsof INTERSPEECH, 2013, pp. 3661–3664.

Lim, CNN-based Bottleneck Feature for Noise Robust Query-by-Example Spoken Term Detection

http://www.apsipa.org/proceedings/2017/CONTENTS/papers2017/14DecThursday/Poster%204/TP-P4.14.pdf

## Konig, Nonlinear discriminant feature extraction for robust text-independent speaker recognition 1998

Bottleneck features extracted by a multi-layer perceptron (MLP) can be used a non-linear feature transformation and di-mentionality reduction [7]

https://www.sri.com/sites/default/files/publications/nonlinear_discriminant_feature_extraction_for_robust.pdf

## Yu, Improved bottleneck features...

Bottleneck features are generated from a multi-layer perceptron in which one of the internal layers has a small number of hidden units, relative to the size of the other layers. This small layer creates a constriction in the network that forces the information pertinent to classification into a low dimensional representation. Bottleneck features are most commonly used in an autoencoder which the neural network is trained to predict the input features themselves

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.368.5220&rep=rep1&type=pdf

D. Yu and M. L. Seltzer, “Improved bottleneck features using pretrained deep neural networks,” inProceedings of INTERSPEECH, 2011, p. 240.

