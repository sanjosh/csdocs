
# 2021 sayak paul

https://docs.google.com/presentation/d/1o4235jSRLDFBrIn8m_qXXfuTgCRmO9zkemcaCgr9S9k/edit#slide=id.gc7cc8aa130_0_13

## resource efficient

sparse training

quantization

distillation from teacher model

weight clustering


## generative deep learning

super-resolution

domain transfer

extrapolation


## self-supervised 
1. Asking a model to be invariant to different views of the same image.
1. Intuitively, the model learns the content that makes two images visually different i.e. a cat and a mountain.

contrastive self-supervised

https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/

https://arxiv.org/abs/2102.06810

## vision transformers and self-attention

https://github.com/facebookresearch/deit

https://github.com/google-research/vision_transformer

https://github.com/jeonsworld/ViT-pytorch

https://tfhub.dev/sayakpaul/collections/vision_transformer/1

https://keras.io/examples/vision/image_classification_with_vision_transformer/

## robust vision models

handle perturbations and corruption in data, OOD data

https://arxiv.org/abs/2105.07581







