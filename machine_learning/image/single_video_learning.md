# Diverse Generation from a Single Video Made Possible

single video generative models have recently emerged [3, 17].

These methods learn a generative video model from a single input
video, in an unsupervised manner. As such, they learn the
distribution of space-time patches within the single input
video and are then able to generate a plethora of new videos
with the same patch distribution

https://nivha.github.io/vgpnn/

https://arxiv.org/pdf/2109.08591.pdf
